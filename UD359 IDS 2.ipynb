{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "path = '/Users/kbrooks/Documents/UD359 IDS/Lesson 2 Data Wrangling/'\n",
      "file_name = 'Master.csv'\n",
      "file_path = path + file_name\n",
      "baseball_data = pandas.read_csv(file_path)\n",
      "\n",
      "# print baseball_data['nameFirst']\n",
      "\n",
      "# Add new column\n",
      "baseball_data['height_plus_weight'] = baseball_data['height'] + baseball_data['weight']\n",
      "\n",
      "# write new csv\n",
      "baseball_data.to_csv(path + 'baseball_data_with_weight_height.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "\n",
      "def add_full_name(path_to_csv, path_to_new_csv):\n",
      "    #Assume you will be reading in a csv file with the same columns that the\n",
      "    #Lahman baseball data set has -- most importantly, there are columns\n",
      "    #called 'nameFirst' and 'nameLast'.\n",
      "    #1) Write a function that reads a csv\n",
      "    \n",
      "    #located at \"path_to_csv\" into a pandas dataframe, adds a new column\n",
      "    #called 'nameFull' with a players full name.\n",
      "    \n",
      "    #For example:\n",
      "    #   for Hank Aaron, nameFull would be 'Hank Aaron', \n",
      "\t#\n",
      "\t#2) Write the data in the pandas dataFrame to a new csv file located at\n",
      "\t#path_to_new_csv\n",
      "    \n",
      "    #WRITE YOUR CODE HERE\n",
      "    \n",
      "    data = pandas.read_csv(path_to_csv)\n",
      "    data['nameFull'] = data['nameFirst'] + ' ' + data['nameLast']\n",
      "    data.to_csv(path_to_new_csv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import pandasql\n",
      "\n",
      "def select_first_50(filename):\n",
      "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
      "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
      "    # column names more closely resemble columns names one might find in a table.\n",
      "    aadhaar_data = pandas.read_csv(filename)\n",
      "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
      "\n",
      "    # Select out the first 50 values for \"registrar\" and \"enrolment_agency\"\n",
      "    # in the aadhaar_data table using SQL syntax. \n",
      "    #\n",
      "    # Note that \"enrolment_agency\" is spelled with one l. Also, the order\n",
      "    # of the select does matter. Make sure you select registrar then enrolment agency\n",
      "    # in your query.\n",
      "    q = \"\"\"\n",
      "    SELECT registrar, enrolment_agency FROM aadhaar_data LIMIT 50;\n",
      "    \"\"\"\n",
      "\n",
      "    #Execute your SQL command against the pandas frame\n",
      "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
      "    return aadhaar_solution"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''SELECT district, SUM(aadhaar_generated) FROM aadhaar_data GROUP BY district;'''\n",
      "'''SELECT district, subdistrict, SUM(aadhaar_generated) FROM aadhaar_data GROUP BY district, subdistrict;'''\n",
      "'''SELECT district, subdistrict, SUM(aadhaar_generated) FROM aadhaar_data WHERE age > 60 GROUP BY district, subdistrict;'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import pandasql\n",
      "\n",
      "def aggregate_query(filename):\n",
      "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
      "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
      "    # column names more closely resemble columns names one might find in a table.\n",
      "    \n",
      "    aadhaar_data = pandas.read_csv(filename)\n",
      "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
      "\n",
      "    # Write a query that will select from the aadhaar_data table how many men and how \n",
      "    # many women over the age of 50 have had aadhaar generated for them in each district\n",
      "    #\n",
      "    # Note that in this quiz, the SQL query keywords are case sensitive. \n",
      "    # For example, if you want to do a sum make sure you type 'sum' rather than 'SUM'.\n",
      "    #\n",
      "\n",
      "    # The possible columns to select from aadhaar data are:\n",
      "    #     1) Registrar\n",
      "    #     2) Enrolment Agency\n",
      "    #     3) State\n",
      "    #     4) District\n",
      "    #     5) Sub District\n",
      "    #     6) Pin Code\n",
      "    #     7) Gender\n",
      "    #     8) Age\n",
      "    #     9) Aadhaar generated\n",
      "    #     10) Enrolment Rejected\n",
      "    #     11) Residents providing email,\n",
      "    #     12) Residents providing mobile number\n",
      "    #\n",
      "    # You can download a copy of the aadhaar data that we are passing \n",
      "    # into this exercise below:\n",
      "    # https://www.dropbox.com/s/vn8t4uulbsfmalo/aadhaar_data.csv\n",
      "        \n",
      "    q = '''SELECT Gender, District, SUM(aadhaar_generated) FROM aadhaar_data WHERE age > 50 GROUP BY Gender, District;'''\n",
      "\n",
      "    # Execute your SQL command against the pandas frame\n",
      "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
      "    return aadhaar_solution    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# API\n",
      "# Representational State Transfer (REST)\n",
      "\n",
      "# last.fm API: http://www.last.fm/api;  JSON data\n",
      "\n",
      "import json\n",
      "import requests\n",
      "\n",
      "url = 'http://ws.audioscrobbler.com/2.0/?method=album.getinfo&api_key=4beab33cc6d65b05800d51f5e83bde1b&artist=Cher&album=Believe&format=json'\n",
      "data = requests.get(url).text\n",
      "data = json.loads(data)\n",
      "print type(data)\n",
      "print data\n",
      "data['artist']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import requests\n",
      "\n",
      "def api_get_request(url):\n",
      "    # In this exercise, you want to call the last.fm API to get a list of the\n",
      "    # top artists in Spain.\n",
      "    #\n",
      "    # Once you've done this, return the name of the number 1 top artist in Spain.\n",
      "    data = requests.get(url).text\n",
      "    data = json.loads(data)\n",
      "    \n",
      "    return data['topartists']['artist'][0]['name']\n",
      "\n",
      "url = 'http://ws.audioscrobbler.com/2.0/?method=geo.getTopArtists&api_key=4beab33cc6d65b05800d51f5e83bde1b&country=Spain&format=json'\n",
      "print api_get_request(url)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Arctic Monkeys\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "path = '/Users/kbrooks/Documents/UD359 IDS/Lesson 2 Data Wrangling/'\n",
      "file_name = 'Master.csv'\n",
      "file_path = path + file_name\n",
      "baseball = pandas.read_csv(file_path)\n",
      "baseball.describe()\n",
      "\n",
      "# note that differences in count among columns is likely due to missing values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>birthYear</th>\n",
        "      <th>birthMonth</th>\n",
        "      <th>birthDay</th>\n",
        "      <th>deathYear</th>\n",
        "      <th>deathMonth</th>\n",
        "      <th>deathDay</th>\n",
        "      <th>weight</th>\n",
        "      <th>height</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 18023.000000</td>\n",
        "      <td> 17842.000000</td>\n",
        "      <td> 17671.000000</td>\n",
        "      <td> 8982.000000</td>\n",
        "      <td> 8981.000000</td>\n",
        "      <td> 8980.000000</td>\n",
        "      <td> 17393.000000</td>\n",
        "      <td> 17449.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>  1929.490817</td>\n",
        "      <td>     6.629750</td>\n",
        "      <td>    15.589667</td>\n",
        "      <td> 1963.111890</td>\n",
        "      <td>    6.490257</td>\n",
        "      <td>   15.552004</td>\n",
        "      <td>   185.244926</td>\n",
        "      <td>    72.222763</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>    40.441637</td>\n",
        "      <td>     3.467046</td>\n",
        "      <td>     8.743129</td>\n",
        "      <td>   30.819271</td>\n",
        "      <td>    3.521970</td>\n",
        "      <td>    8.789343</td>\n",
        "      <td>    20.773669</td>\n",
        "      <td>     2.594336</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>  1831.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td> 1872.000000</td>\n",
        "      <td>    1.000000</td>\n",
        "      <td>    1.000000</td>\n",
        "      <td>    65.000000</td>\n",
        "      <td>    43.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>  1894.000000</td>\n",
        "      <td>     4.000000</td>\n",
        "      <td>     8.000000</td>\n",
        "      <td> 1942.000000</td>\n",
        "      <td>    3.000000</td>\n",
        "      <td>    8.000000</td>\n",
        "      <td>   170.000000</td>\n",
        "      <td>    71.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>  1934.000000</td>\n",
        "      <td>     7.000000</td>\n",
        "      <td>    15.000000</td>\n",
        "      <td> 1966.000000</td>\n",
        "      <td>    6.000000</td>\n",
        "      <td>   15.000000</td>\n",
        "      <td>   185.000000</td>\n",
        "      <td>    72.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>  1967.000000</td>\n",
        "      <td>    10.000000</td>\n",
        "      <td>    23.000000</td>\n",
        "      <td> 1988.000000</td>\n",
        "      <td>   10.000000</td>\n",
        "      <td>   23.000000</td>\n",
        "      <td>   195.000000</td>\n",
        "      <td>    74.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>  1993.000000</td>\n",
        "      <td>    12.000000</td>\n",
        "      <td>    31.000000</td>\n",
        "      <td> 2014.000000</td>\n",
        "      <td>   12.000000</td>\n",
        "      <td>   31.000000</td>\n",
        "      <td>   320.000000</td>\n",
        "      <td>    83.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "          birthYear    birthMonth      birthDay    deathYear   deathMonth  \\\n",
        "count  18023.000000  17842.000000  17671.000000  8982.000000  8981.000000   \n",
        "mean    1929.490817      6.629750     15.589667  1963.111890     6.490257   \n",
        "std       40.441637      3.467046      8.743129    30.819271     3.521970   \n",
        "min     1831.000000      1.000000      1.000000  1872.000000     1.000000   \n",
        "25%     1894.000000      4.000000      8.000000  1942.000000     3.000000   \n",
        "50%     1934.000000      7.000000     15.000000  1966.000000     6.000000   \n",
        "75%     1967.000000     10.000000     23.000000  1988.000000    10.000000   \n",
        "max     1993.000000     12.000000     31.000000  2014.000000    12.000000   \n",
        "\n",
        "          deathDay        weight        height  \n",
        "count  8980.000000  17393.000000  17449.000000  \n",
        "mean     15.552004    185.244926     72.222763  \n",
        "std       8.789343     20.773669      2.594336  \n",
        "min       1.000000     65.000000     43.000000  \n",
        "25%       8.000000    170.000000     71.000000  \n",
        "50%      15.000000    185.000000     72.000000  \n",
        "75%      23.000000    195.000000     74.000000  \n",
        "max      31.000000    320.000000     83.000000  "
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Dealing with missing data\n",
      "* listwise deletion - takes an entire record out  (like complete sets in R)\n",
      "* pairwise deletion - excludes that record only from the calculation that can't be performed\n",
      "\n",
      "Imputation might be a better idea\n",
      "* always biases injected\n",
      "* there are sophisticated ways of doing it out there\n",
      "* simple ways\n",
      "    * mean replacement - we don't change the overall mean, but it does hurt pairwise\n",
      "    * linear regression - equation to do it. overemphasize existing trends in the data - all imputed values will add to trend\n",
      "    *"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import *\n",
      "import numpy\n",
      "\n",
      "def imputation(filename):\n",
      "    # Pandas dataframes have a method called 'fillna(value)', such that you can\n",
      "    # pass in a single value to replace any NAs in a dataframe or series. You\n",
      "    # can call it like this: \n",
      "    #     dataframe['column'] = dataframe['column'].fillna(value)\n",
      "    #\n",
      "    # Using the numpy.mean function, which calculates the mean of a numpy\n",
      "    # array, impute any missing values in our Lahman baseball\n",
      "    # data sets 'weight' column by setting them equal to the average weight.\n",
      "    # \n",
      "    # You can access the 'weight' colum in the baseball data frame by\n",
      "    # calling baseball['weight']\n",
      "\n",
      "    baseball = pandas.read_csv(filename)\n",
      "    \n",
      "    #YOUR CODE GOES HERE\n",
      "    value = numpy.mean(baseball['weight'])\n",
      "    baseball['weight'] = baseball['weight'].fillna(value)\n",
      "    return baseball\n",
      "\n",
      "path = '/Users/kbrooks/Documents/UD359 IDS/Lesson 2 Data Wrangling/'\n",
      "file_name = 'Master.csv'\n",
      "filename = path + file_name\n",
      "\n",
      "#print imputation(filename)['weight']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0     205\n",
        "1     180\n",
        "2     190\n",
        "3     190\n",
        "4     184\n",
        "5     220\n",
        "6     192\n",
        "7     170\n",
        "8     175\n",
        "9     169\n",
        "10    190\n",
        "11    180\n",
        "12    200\n",
        "13    190\n",
        "14    200\n",
        "...\n",
        "18161    180\n",
        "18162    210\n",
        "18163    200\n",
        "18164    185\n",
        "18165    175\n",
        "18166    195\n",
        "18167    190\n",
        "18168    230\n",
        "18169    215\n",
        "18170    220\n",
        "18171    220\n",
        "18172    182\n",
        "18173    173\n",
        "18174    195\n",
        "18175    160\n",
        "Name: weight, Length: 18176, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Assignment 2\n",
      "1. get data from weather underground web site\n",
      "2. get a sense of the data using sql queries\n",
      "3. clean up and process the data"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}