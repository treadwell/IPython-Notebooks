{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pairwise t-test\n",
      "\n",
      "import scipy.stats\n",
      "import numpy as np\n",
      "\n",
      "list_1 = np.random.normal(0, 1, 100)\n",
      "list_2 = np.random.normal(3, 2, 100)\n",
      "\n",
      "scipy.stats.ttest_ind(list_1, list_2, equal_var = False)\n",
      "# the equal_var = False makes this Welch's t-test\n",
      "# returns a tuple with first value the t value and the second the p value\n",
      "# for a two-sided t test.  Only testing where the means are different\n",
      "\n",
      "# one-sided t-test:  The two-sided p value is half of the one-side value,\n",
      "# so double the p value\n",
      "\n",
      "# so for a > test, p/2 < pcritical; t > 0\n",
      "# for a < test, p/2 < pcritical; t < 0\n",
      "\n",
      "# assumes distribution is normal\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "(array(-11.749746606989806), 3.3670508025459199e-22)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import scipy.stats\n",
      "import pandas\n",
      "\n",
      "def compare_averages(filename):\n",
      "    \"\"\"\n",
      "    Performs a t-test on two sets of baseball data (left-handed and right-handed hitters).\n",
      "\n",
      "    You will be given a csv file that has three columns.  A player's\n",
      "    name, handedness (L for lefthanded or R for righthanded) and their\n",
      "    career batting average (called 'avg'). You can look at the csv\n",
      "    file via the following link:\n",
      "    https://www.dropbox.com/s/xcn0u2uxm8c4n6l/baseball_data.csv\n",
      "    \n",
      "    Write a function that will read that the csv file into a pandas data frame,\n",
      "    and run Welch's t-test on the two cohorts defined by handedness.\n",
      "    \n",
      "    One cohort should be a data frame of right-handed batters. And the other\n",
      "    cohort should be a data frame of left-handed batters.\n",
      "    \n",
      "    We have included the scipy.stats library to help you write\n",
      "    or implement Welch's t-test:\n",
      "    http://docs.scipy.org/doc/scipy/reference/stats.html\n",
      "    \n",
      "    With a significance level of 95%, if there is no difference\n",
      "    between the two cohorts, return a tuple consisting of\n",
      "    True, and then the tuple returned by scipy.stats.ttest.  \n",
      "    \n",
      "    If there is a difference, return a tuple consisting of\n",
      "    False, and then the tuple returned by scipy.stats.ttest.\n",
      "    \n",
      "    For example, the tuple that you return may look like:\n",
      "    (True, (9.93570222, 0.000023))\n",
      "    \"\"\"\n",
      "    data = pandas.read_csv(filename)\n",
      "\n",
      "    data_RH = data[data['handedness'] == \"R\"]\n",
      "    avg_RH = list(data_RH['avg'])\n",
      "    data_LH = data[data['handedness'] == \"L\"]\n",
      "    avg_LH = list(data_LH['avg'])\n",
      "    stats = scipy.stats.ttest_ind(avg_RH, avg_LH, equal_var = False)\n",
      "    p = stats[1]\n",
      "    if p < 0.05:\n",
      "        diff = False  #  means we reject the null hypothesis and there is a difference\n",
      "    else:\n",
      "        diff = True  #  means we accept the null hypothesis that there isn't a difference\n",
      "    return tuple([diff, stats])\n",
      "\n",
      "path = '/Users/kbrooks/Documents/UD359 IDS/Lesson 3 Data Analysis/'\n",
      "file_name = 'baseball_data.csv'\n",
      "\n",
      "filename = path + file_name\n",
      "\n",
      "print compare_averages(filename)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(False, (array(-3.9867064465971422), 7.4823915909703493e-05))\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "What happens when you can't assume your data is drawn from any particular distribution?  Use the Mann-Whitney U test (also called the Mann-Whitney-Wilcoxon test).  Tests the null hypothesis that two populations are the same."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_1 = np.random.normal(0, 1, 100)\n",
      "list_2 = np.random.normal(3, 2, 100)\n",
      "\n",
      "u, p = scipy.stats.mannwhitneyu(list_1,list_2)\n",
      "\n",
      "print u, p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "611.0 3.97736574744e-27\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  plot data or Q-Q plot\n",
      "# Shapiro-Wilk Test to test if the population is normal\n",
      "\n",
      "list_1 = np.random.normal(0, 1, 100)\n",
      "\n",
      "w, p = scipy.stats.shapiro(list_1)\n",
      "\n",
      "print w, p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.979426860809 0.11993599683\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# implement gradient descent\n",
      "\n",
      "import numpy\n",
      "import pandas\n",
      "\n",
      "def compute_cost(features, values, theta):\n",
      "    \"\"\"\n",
      "    Compute the cost function given a set of features / values, and values for our thetas.\n",
      "    \"\"\"\n",
      "    m = len(values)\n",
      "    sum_of_square_errors = numpy.square(numpy.dot(features, theta) - values).sum()\n",
      "    cost = sum_of_square_errors / (2*m)\n",
      "\n",
      "    return cost\n",
      "\n",
      "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
      "    \"\"\"\n",
      "    Perform gradient descent given a data set with an arbitrary number of features.\n",
      "    \"\"\"\n",
      "    cost_history = []\n",
      "    m = len(values) * 1.0 # to avoid integer division later\n",
      "    \n",
      "    for i in range(num_iterations):\n",
      "        # calculate cost\n",
      "        cost = compute_cost(features, values, theta)\n",
      "    \n",
      "        # append cost to history\n",
      "        cost_history.append(cost)\n",
      "    \n",
      "        # calc new theta\n",
      "        pred = numpy.dot(features, theta)\n",
      "        theta = theta + alpha * (1/m) * numpy.dot((values - pred), features)\n",
      "\n",
      "    return theta, pandas.Series(cost_history)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}